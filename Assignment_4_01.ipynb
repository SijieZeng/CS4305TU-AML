{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"306a8b28901746869606b8fc9e0d579c","source_hash":"710004be","execution_start":1632728804170,"execution_millis":20814,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"!pip install aif360\n!pip install fairlearn\n!pip install tensorflow\n!pip install lime","block_group":"306a8b28901746869606b8fc9e0d579c","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: aif360 in /root/venv/lib/python3.7/site-packages (0.4.0)\nRequirement already satisfied: scikit-learn>=0.22.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from aif360) (0.24.2)\nRequirement already satisfied: matplotlib in /shared-libs/python3.7/py/lib/python3.7/site-packages (from aif360) (3.4.3)\nRequirement already satisfied: pandas>=0.24.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from aif360) (1.2.5)\nRequirement already satisfied: scipy<1.6.0,>=1.2.0 in /root/venv/lib/python3.7/site-packages (from aif360) (1.5.4)\nRequirement already satisfied: numpy>=1.16 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from aif360) (1.19.5)\nRequirement already satisfied: tempeh in /root/venv/lib/python3.7/site-packages (from aif360) (0.1.12)\nRequirement already satisfied: pytz>=2017.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pandas>=0.24.0->aif360) (2021.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pandas>=0.24.0->aif360) (2.8.2)\nRequirement already satisfied: six>=1.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.16.0)\nRequirement already satisfied: joblib>=0.11 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.22.1->aif360) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.22.1->aif360) (2.2.0)\nRequirement already satisfied: pillow>=6.2.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib->aif360) (8.3.2)\nRequirement already satisfied: cycler>=0.10 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib->aif360) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from matplotlib->aif360) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib->aif360) (1.3.2)\nRequirement already satisfied: memory-profiler in /root/venv/lib/python3.7/site-packages (from tempeh->aif360) (0.58.0)\nRequirement already satisfied: requests in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tempeh->aif360) (2.26.0)\nRequirement already satisfied: pytest in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tempeh->aif360) (6.2.5)\nRequirement already satisfied: shap in /root/venv/lib/python3.7/site-packages (from tempeh->aif360) (0.39.0)\nRequirement already satisfied: psutil in /root/venv/lib/python3.7/site-packages (from memory-profiler->tempeh->aif360) (5.8.0)\nRequirement already satisfied: toml in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pytest->tempeh->aif360) (0.10.2)\nRequirement already satisfied: iniconfig in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pytest->tempeh->aif360) (1.1.1)\nRequirement already satisfied: attrs>=19.2.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pytest->tempeh->aif360) (21.2.0)\nRequirement already satisfied: importlib-metadata>=0.12 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pytest->tempeh->aif360) (4.8.1)\nRequirement already satisfied: packaging in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pytest->tempeh->aif360) (21.0)\nRequirement already satisfied: py>=1.8.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pytest->tempeh->aif360) (1.10.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pytest->tempeh->aif360) (1.0.0)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->tempeh->aif360) (3.5.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->tempeh->aif360) (3.10.0.2)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->tempeh->aif360) (2.0.6)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->tempeh->aif360) (3.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->tempeh->aif360) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->tempeh->aif360) (2021.5.30)\nRequirement already satisfied: slicer==0.0.7 in /root/venv/lib/python3.7/site-packages (from shap->tempeh->aif360) (0.0.7)\nRequirement already satisfied: cloudpickle in /root/venv/lib/python3.7/site-packages (from shap->tempeh->aif360) (2.0.0)\nRequirement already satisfied: numba in /root/venv/lib/python3.7/site-packages (from shap->tempeh->aif360) (0.54.0)\nRequirement already satisfied: tqdm>4.25.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from shap->tempeh->aif360) (4.62.3)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.7/site-packages (from numba->shap->tempeh->aif360) (58.0.4)\nRequirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /root/venv/lib/python3.7/site-packages (from numba->shap->tempeh->aif360) (0.37.0)\nRequirement already satisfied: fairlearn in /root/venv/lib/python3.7/site-packages (0.7.0)\nRequirement already satisfied: numpy>=1.17.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fairlearn) (1.19.5)\nRequirement already satisfied: scipy>=1.4.1 in /root/venv/lib/python3.7/site-packages (from fairlearn) (1.5.4)\nRequirement already satisfied: scikit-learn>=0.22.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fairlearn) (0.24.2)\nRequirement already satisfied: pandas>=0.25.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from fairlearn) (1.2.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pandas>=0.25.1->fairlearn) (2021.1)\nRequirement already satisfied: six>=1.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.16.0)\nRequirement already satisfied: joblib>=0.11 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.22.1->fairlearn) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.22.1->fairlearn) (2.2.0)\nRequirement already satisfied: tensorflow in /shared-libs/python3.7/py/lib/python3.7/site-packages (2.4.1)\nCollecting typing-extensions~=3.7.4\n  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nRequirement already satisfied: wrapt~=1.12.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: gast==0.3.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (0.3.3)\nCollecting six~=1.15.0\n  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\nRequirement already satisfied: opt-einsum~=3.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: tensorboard~=2.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: astunparse~=1.6.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: numpy~=1.19.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (1.19.5)\nRequirement already satisfied: wheel~=0.35 in /root/venv/lib/python3.7/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: h5py~=2.10.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (2.10.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (1.12)\nRequirement already satisfied: termcolor~=1.1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: protobuf>=3.9.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (3.17.3)\nRequirement already satisfied: absl-py~=0.10 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (0.14.0)\nRequirement already satisfied: grpcio~=1.32.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (1.32.0)\nRequirement already satisfied: google-pasta~=0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.0.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.26.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.4.6)\nRequirement already satisfied: setuptools>=41.0.0 in /root/venv/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (58.0.4)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.6.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.35.0)\nRequirement already satisfied: markdown>=2.6.8 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\nRequirement already satisfied: importlib-metadata in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (4.8.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.0.6)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.7)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2021.5.30)\nRequirement already satisfied: oauthlib>=3.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.1)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.5.0)\nInstalling collected packages: typing-extensions, six\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.10.0.2\n    Not uninstalling typing-extensions at /shared-libs/python3.7/py-core/lib/python3.7/site-packages, outside environment /root/venv\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: six\n    Found existing installation: six 1.16.0\n    Not uninstalling six at /shared-libs/python3.7/py-core/lib/python3.7/site-packages, outside environment /root/venv\n    Can't uninstall 'six'. No files were found to uninstall.\nSuccessfully installed six-1.15.0 typing-extensions-3.7.4.3\nRequirement already satisfied: lime in /root/venv/lib/python3.7/site-packages (0.2.0.1)\nRequirement already satisfied: tqdm in /shared-libs/python3.7/py/lib/python3.7/site-packages (from lime) (4.62.3)\nRequirement already satisfied: matplotlib in /shared-libs/python3.7/py/lib/python3.7/site-packages (from lime) (3.4.3)\nRequirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from lime) (1.19.5)\nRequirement already satisfied: scikit-learn>=0.18 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from lime) (0.24.2)\nRequirement already satisfied: scipy in /root/venv/lib/python3.7/site-packages (from lime) (1.5.4)\nRequirement already satisfied: scikit-image>=0.12 in /root/venv/lib/python3.7/site-packages (from lime) (0.18.3)\nRequirement already satisfied: PyWavelets>=1.1.1 in /root/venv/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (1.1.1)\nRequirement already satisfied: imageio>=2.3.0 in /root/venv/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2.9.0)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (8.3.2)\nRequirement already satisfied: networkx>=2.0 in /root/venv/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2.6.3)\nRequirement already satisfied: tifffile>=2019.7.26 in /root/venv/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2021.8.30)\nRequirement already satisfied: cycler>=0.10 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib->lime) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from matplotlib->lime) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.7 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from matplotlib->lime) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib->lime) (1.3.2)\nRequirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->lime) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.18->lime) (2.2.0)\nRequirement already satisfied: joblib>=0.11 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.18->lime) (1.0.1)\nPython 3.7.11\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/fee91e64-2989-437c-bc42-cc5f70afbc04","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"2a36689e7a704fa383eded060dbef5df","source_hash":"b31fd813","execution_start":1632728824990,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"\n","block_group":"2a36689e7a704fa383eded060dbef5df","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"d2113f00ace1461697c9233057414b95","deepnote_cell_type":"markdown"},"source":"![tud_logo.jpg](attachment:tud_logo.jpg)","block_group":"d2113f00ace1461697c9233057414b95"},{"cell_type":"markdown","metadata":{"cell_id":"7effec41de784ebe8ddb202be5a6d4fa","deepnote_cell_type":"markdown"},"source":"# Assignment 4 - ML Ethical and Societal perspective\nWeek 4 - CS4305TU Applied Machine Learning <br>","block_group":"7effec41de784ebe8ddb202be5a6d4fa"},{"cell_type":"markdown","metadata":{"cell_id":"69c8a2e263264bbfb7e89d5231b136c7","deepnote_cell_type":"markdown"},"source":"By <b> Nadia Metoui </b> and <b> Ibo van de Poel </b><br>\nFaculty of Technology, Policy, and Management (TPM)","block_group":"69c8a2e263264bbfb7e89d5231b136c7"},{"cell_type":"markdown","metadata":{"cell_id":"3028e29647ba40e9908454e5272b3169","deepnote_cell_type":"markdown"},"source":"***Submission Instructions***\n - Answer the questions (code or text) in this Notebook \n - Rename the Notebook by adding your group number\n - Send the your answers both in ipynb and HTML format","block_group":"3028e29647ba40e9908454e5272b3169"},{"cell_type":"markdown","metadata":{"cell_id":"67bf6e94791f47bd80d8c1e7becba4d0","deepnote_cell_type":"markdown"},"source":"<H2>Part I: Socio-technical abstraction of an ML-based system</H2>\n<i>LO-1: Identify and analyse ethical issues related to ML.<i><br>\n<i>LO-2: Discuss machine learning fairness in the broader context of sociotechnical systems.</i>","block_group":"67bf6e94791f47bd80d8c1e7becba4d0"},{"cell_type":"markdown","metadata":{"cell_id":"2ec538aef74746f89733a997a4e18197","deepnote_cell_type":"markdown"},"source":"Q1: Analyse and discuss the potential harmes of an ML-based Recommendation System using the Taxonomy and Model of Milan et <i>al.</i> (2020).\nTo help with your analysis we provide 3 case studies you can find in Brightspace\n- Tiktok recommendation systems (See Case Study 1)\n- Youtube recommendation systems (See Case Study 2)\n- Tinder recommendation systems (See Case Study 3)","block_group":"2ec538aef74746f89733a997a4e18197"},{"cell_type":"markdown","metadata":{"cell_id":"8b4befa7810e42468d54e7f86ac0cf03","deepnote_cell_type":"markdown"},"source":"Choose <b>one of the  Case Studies</b> above and answer the following questions based on your knowledge of the platform and the information you read on the case study:\n- a) Briefly summarise, what seems to be the ethical/social issue tackled in the use case you selected. \n- b) Who are the stakeholdes in this case? Name and describe at lease one stakeholdes from each category? \n- c) Briefly explain what are the intrests of each stakeholde and value they derive from using the recommendation system.\n- d) Briefly explain what are the potential harmes for each stakeholde and how are they impacting them?","block_group":"8b4befa7810e42468d54e7f86ac0cf03"},{"cell_type":"markdown","metadata":{"cell_id":"89d7ecbc0acb4fdcb634f0f4f59cf320","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Consider all stakholders depicted in the figure below. Use the categorization of (Milano 2020).<br>\nThe full paper as well as a cheatsheet can be found in Brightspace.\n</div>","block_group":"89d7ecbc0acb4fdcb634f0f4f59cf320"},{"cell_type":"markdown","metadata":{"cell_id":"0b9092c234054da6872482819ddb8c48","deepnote_cell_type":"markdown"},"source":"![milano_model-2.png](attachment:milano_model-2.png)","block_group":"0b9092c234054da6872482819ddb8c48"},{"cell_type":"markdown","metadata":{"cell_id":"c484af0f35764b49b2f5a9072c76e225","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n    \n<b>Types of Harm</b>\n- <u>on Utility</u>: Utility is the value each party is expecting to derive from using a the ML-based system. The impact or harm to Utility can be assessed using quantifiable metrics (e.g., time, money)\n- <u>on Rights</u>: legal, social, or ethical entitlements (e.g., privacy autonomy, equality)  The impact or harm to Ritghts is very hard to quantify.\n\n<br>\n\n<b>Types of Impacts</b>\n- <u>Immediate harm</u>: the recommendation or the ML-based system has an immediate and direct negative impact e.g., errors (incorrect outputs), out of context results (inappropriate outputs), opacity (uninterpretabel output).\n- <u>Exposure to Risk</u>: the recommendation or the ML-based system exposes the Stakeholder(s) to latent or potential negative impacts. Even if these impacts do not materialize, exposure to such risks is considered unethical.\n</div>","block_group":"c484af0f35764b49b2f5a9072c76e225"},{"cell_type":"markdown","metadata":{"cell_id":"790ab725116d486ea3081cf12dbcef8a","deepnote_cell_type":"markdown"},"source":"For my analysis, I have chosen the third case study, dealing with Tinder. \n\na) The main ethical issue which is presented in the case study is the use of a desirability ranking in the recommendation algorithm. This is a concept that was mainly taken from chess' Elo ranking. Each account has a certain 'desirability score' which increases when you are liked by a person with a higher score, and decreases when someone with a lower score likes you. Additionally, Tinder also has a patent on a matching process that groups people by wealth, social status, ethnicity, religious preferences, intelligence and attractiveness, and encourage dates between those of similar\nbackgrounds. Meanwhile, as a user you are never informed of this. All you can control is the sex, age-range and proximity of other profiles. Tinder could be much more open about how certain recommendations appear in your feed, by giving the factors on which you were matched. All these factors present some clear ethical issues, and can also have a negative impact on some social issues.\n\nb & c) Unlike the other two case studies, in this one the users of Tinders fulfil two of the stakeholder categories. Users belong to the 'providers' category because they create profiles with their interests, preferences and photos. These profiles are then released into the potential matching pool, and their creators have a keen interest in their profile being suggested to others as much as possible. Interestingly, however, these 'others' are also users just like themselves, so Tinder's users also fall in the 'users' category of stakeholders. They receive and act upon recommendations by being presented other profiles, and swiping left or right. As a rejecting swipe to the left is little more than wasted time, they obviously want the best recommendations possible. Finally, we have the company Tinder as a stakeholder from the 'system' category. They provide the recommendations to all its users, and want to keep the platform going. It is important to note that from a business standpoint it may not be in Tinder's best interest to provide the perfect recommendations, as that can mean their users start dating and leave their platform. Still, they want to provide good enough matches to keep people engaged. Society as a stakeholder has the obvious desired effect of creating love and new relationships between people who otherwise might have never met.\n\nd) For this case study, in particular, it is difficult to clearly distinguish users in the 'provider' and 'user' stakeholder category, because their desires and expectations overlap a lot. Therefore, I will treat them as one group for this part. For users in general on Tinder, the utility they expect to derive from Tinder's recommendation system is clear: make the first steps towards building a (romantical) relationship with a different person. Ideally, these recommendations would be unbiased and fair, but due to Tinder's opaque systems, it is difficult to see whether they really are for users. And indeed, as Tinder's patents and statement imply, they most likely do make subgroups of users based on social status, ethnicity, attractiveness and many other such facets. This is an example of immediate harm, and directly impacts the (limited) choices the users are presented with. For the users, the harm to the utility can be defined as not only all the time lost in the app spent talking to suboptimal matches, but they also have millions of people who pay for features like extra liked to spend. Something with perhaps an even greater ethical impact is that people are exposed to risks such as loss of confidence, anxiety, or feeling much worse about themselves when they are unsuccessful on the platform. \nFor Tinder as the platform, there are also some issues. Through their matching process, they likely reinforce harmful biases and promote discrimination. In my opinion, their system needs much more transparency in how their recommendations are created, and let the users have a much bigger role in defining their desired traits. Their current process uses strategies that reinforce negative materialism and gender-role stereotypes, the latter most prominently in heterosexual couples. Let us take the example from the case study: a female will be more likely to be recommended to a male user if she is 10 years younger than him, earns 10.000$ less per year and has a bachelor’s degree. The immediate effect is that both of these persons will get something that reinforces existing biases instead of their potential optimal match, and the exposure of risk is that the unfairness in society is upheld and even promotes them. There is much to be gained in this case study regarding ethical/social issues.","block_group":"790ab725116d486ea3081cf12dbcef8a"},{"cell_type":"markdown","metadata":{"cell_id":"297b880bb570446faef28bdea90b9868","deepnote_cell_type":"markdown"},"source":"<br><br>","block_group":"297b880bb570446faef28bdea90b9868"},{"cell_type":"markdown","metadata":{"cell_id":"894a56bba7204e2d9ee12e295d87682f","deepnote_cell_type":"markdown"},"source":"<H2> Part II. Detecting and Mitigating bias*.</H2>\n<i>LO-3: Apply state-of-the-art debiasing approaches to identify and mitigate risks of biases in your ML-based system.</i><br>\n<i>LO-4. Compare different implementations of fairness metrics and unfairness mitigation approaches.  \n</i>","block_group":"894a56bba7204e2d9ee12e295d87682f"},{"cell_type":"markdown","metadata":{"cell_id":"0dc9dc0101eb4bd3aab6890cb8672932","deepnote_cell_type":"markdown"},"source":"*Acknowledgement: Part II of this assignment is largely based on the code developed by <i><b>Agathe Balayn</b></i> and <i><b>Seda Gürses</b></i>","block_group":"0dc9dc0101eb4bd3aab6890cb8672932"},{"cell_type":"markdown","metadata":{"cell_id":"8d71edd1e5e74b739354ad2663fd3a83","deepnote_cell_type":"markdown"},"source":"In this part of the assignment, you will be exploring a use case where a Bank wants to develop an ML-based ADM (automate decision system) to decide whether to <b>grant</b> or <b>not to grant</b> a loan to a given applicant. To do so the Bank uses historical data containing multiple application records, characterized by information about the loan applicants (e.g., age, gender, personal situation) and information about the loan (e.g., amount, duration, purpose). Each application is labeled <i> good credit </i> if the loan had been reimbursed or <i>bad credit</i> if the loan has not been reimbursed or if there where several issues with the reimbursement.\n\nTo simulate this scenario we will build a classifier to disinguich between good and bad loans (or credits). We will train the classifier using the <i><b>German credit data</b></i> (you can information about the dataset and its attributes here: (https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc).<br>\nAnd you can download the dataset here:\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data<br>\n\n\nYou will be requested to take a closer look at the data and identify biases. We will use some tools form <i><b>AIF360 toolkit</b></i><br>(https://aif360.mybluemix.net/) a toolkit developed by IBM to detect and mitigate \"bias\" and \"unfairness\".\n\nSteps of Part II\n- Step 1: Set-up (Provided)\n- Step 2: Explore and familiarize with the dataset\n- Step 3: Pre-processing Biases: Protected attributes, proxies, data representation and skews  \n- Step 4: In-processing Biases: Identify and Mitigate","block_group":"8d71edd1e5e74b739354ad2663fd3a83"},{"cell_type":"markdown","metadata":{"cell_id":"a306f9b884c44f888ad5f437fdd086e3","deepnote_cell_type":"markdown"},"source":"<H3>Setp 2: Set-up</H3>\n\nYou first need to install the required libraries for this part.  The main libraries are the `aif360`,  `lime`, and`sklearn` ones. We also recommend using `numpy` and `pandas` to easily manipulate and explore the data.","block_group":"a306f9b884c44f888ad5f437fdd086e3"},{"cell_type":"markdown","metadata":{"cell_id":"eb6ade98ad554b798a6360a67eb11006","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-danger\">\n<b>Note:</b> Uncomment and run the next cell if you have not previously installed the libraries.\n</div>\n","block_group":"eb6ade98ad554b798a6360a67eb11006"},{"cell_type":"markdown","metadata":{"cell_id":"ba6d6abaacd54e2ba5e9cb07f460a4db","deepnote_cell_type":"markdown"},"source":"<b>Installing required libraries</b>","block_group":"ba6d6abaacd54e2ba5e9cb07f460a4db"},{"cell_type":"markdown","metadata":{"cell_id":"ec2f5433595c41ad929eb9515036b957","deepnote_cell_type":"markdown"},"source":"<b>Loading required libraries</b>","block_group":"ec2f5433595c41ad929eb9515036b957"},{"cell_type":"code","metadata":{"cell_id":"3082c556054f4844a213f324e5cdcb3c","source_hash":"ecc882f3","execution_start":1632728972096,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import Markdown, display\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nnp.random.seed(0)\n\nfrom aif360.datasets import GermanDataset\nfrom aif360.metrics import BinaryLabelDatasetMetric\nfrom aif360.metrics import ClassificationMetric\nfrom aif360.algorithms.inprocessing import MetaFairClassifier\n\nfrom aif360.datasets.lime_encoder import LimeEncoder\n\nimport lime\nimport lime.lime_tabular","block_group":"3082c556054f4844a213f324e5cdcb3c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"52b7f8a4091b472d9de933a42a0129b7","deepnote_cell_type":"markdown"},"source":"<b>Loading the dataset</b>\n\nHere, we will load the <i><b>German credit data</b></i> in a format that is compatible with the use of the <i><b>AIF360 toolkit</b></i>. For this, you need to make use of the already implemented class of the toolkit `GermanDataset()`.\n\nBecause the data available is encoded in a complex way, we provide you with the code to preprocess it, in the function `custom_preprocessing()`. We also provide you with an example on how to actually load the data using the `GermanDataset()` class, in `preproc_and_load_data_german()`. ","block_group":"52b7f8a4091b472d9de933a42a0129b7"},{"cell_type":"code","metadata":{"cell_id":"3462275b0d464534a68a94611422bcbb","source_hash":"3292b830","execution_start":1632728833989,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def preproc_and_load_data_german():\n    \"\"\"\n    Load and pre-process german credit dataset.\n    Args: -\n    Returns:\n        GermanDataset: An instance of GermanDataset with required pre-processing.\n    \"\"\"\n    def custom_preprocessing(df):\n        \"\"\" Custom pre-processing for German Credit Data\n        \"\"\"\n\n        def group_credit_hist(x):\n            if x in ['A30', 'A31', 'A32']:\n                return 'None/Paid'\n            elif x == 'A33':\n                return 'Delay'\n            elif x == 'A34':\n                return 'Other'\n            else:\n                return 'NA'\n\n        def group_employ(x):\n            if x == 'A71':\n                return 'Unemployed'\n            elif x in ['A72', 'A73']:\n                return '1-4 years'\n            elif x in ['A74', 'A75']:\n                return '4+ years'\n            else:\n                return 'NA'\n\n        def group_savings(x):\n            if x in ['A61', 'A62']:\n                return '<500'\n            elif x in ['A63', 'A64']:\n                return '500+'\n            elif x == 'A65':\n                return 'Unknown/None'\n            else:\n                return 'NA'\n\n        def group_status(x):\n            if x in ['A11', 'A12']:\n                return '<200'\n            elif x in ['A13']:\n                return '200+'\n            elif x == 'A14':\n                return 'None'\n            else:\n                return 'NA'\n        \n        def group_personal_status(x):\n            if x in ['A91']:\n                return 'divorced/separated'\n            elif x in ['A92']:\n                return 'divorced/separated/married'\n            elif x in ['A93', 'A95']:\n                return 'single'\n            elif x in ['A94']:\n                return 'married/widowed'\n            else:\n                return 'NA'\n        #print(df)\n        #print(df.shape)\n        #print(df.isnull().sum().sum())\n        #print(df.isin(['NA']).sum(axis=0))\n        status_map = {'A91': 1.0, 'A93': 1.0, 'A94': 1.0,\n                    'A92': 0.0, 'A95': 0.0}\n        \n        df['sex'] = df['personal_status'].replace(status_map)\n        \n\n        # group credit history, savings, and employment\n        df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n        df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n        df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n        #df['age'] = df['age'].apply(lambda x: np.float(x >= 26))\n        df['status'] = df['status'].apply(lambda x: group_status(x))\n        df['personal_status'] = df['personal_status'].apply(lambda x: group_personal_status(x))\n        #print(df.isin(['NA']).sum(axis=0))\n        \n        print(df)\n        df.to_csv(\"german_credit_data_processed_v2.csv\")\n        return df\n\n    # Feature partitions\n    XD_features = ['number_of_credits', 'telephone',\n                     'foreign_worker', 'people_liable_for', 'skill_level', 'credit_history', 'installment_plans', 'residence_since', 'property', 'other_debtors', 'purpose', 'savings', 'employment', 'sex', 'age', 'personal_status', 'month']\n    D_features = ['sex', 'age'] \n    Y_features = ['credit']\n    X_features = list(set(XD_features)-set(D_features))\n    categorical_features = ['installment_plans', 'telephone',\n                     'foreign_worker', 'skill_level', 'credit_history', 'property', \n                            'other_debtors', 'purpose', 'savings', 'employment', 'personal_status']\n\n    # privileged classes\n    all_privileged_classes = {\"sex\": [1.0],\n                              \"age\": lambda x: x > 25}\n\n    # protected attribute maps\n    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n                                    \"age\": {1.0: 'Old', 0.0: 'Young'}}\n\n    return GermanDataset(\n        label_name=Y_features[0],\n        favorable_classes=[1],\n        protected_attribute_names=D_features,\n        privileged_classes=[all_privileged_classes[x] for x in D_features],\n        instance_weights_name=None,\n        categorical_features=categorical_features,\n        features_to_keep=X_features+Y_features+D_features,\n        features_to_drop=[],\n        metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n                   'protected_attribute_maps': [all_protected_attribute_maps[x]\n                                for x in D_features]},\n        custom_preprocessing=custom_preprocessing)","block_group":"3462275b0d464534a68a94611422bcbb","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e12589fc55034526b3871830c215d5e0","source_hash":"70a1e072","execution_start":1632728833996,"execution_millis":2561,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"!mkdir /usr/lib/python3.7/dist-packages/aif360/data/raw/german\n!cp /work/german.data /usr/lib/python3.7/dist-packages/aif360/data/raw/german\n!cp /work/german.doc /usr/lib/python3.7/dist-packages/aif360/data/raw/german","block_group":"e12589fc55034526b3871830c215d5e0","execution_count":null,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘/usr/lib/python3.7/dist-packages/aif360/data/raw/german’: No such file or directory\ncp: cannot create regular file '/usr/lib/python3.7/dist-packages/aif360/data/raw/german': No such file or directory\ncp: cannot create regular file '/usr/lib/python3.7/dist-packages/aif360/data/raw/german': No such file or directory\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/25142a17-822b-4e6d-82a7-6fb249bbac05","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"69af5017f9324bd6a43405818e259c8c","deepnote_cell_type":"markdown"},"source":"<br><br>","block_group":"69af5017f9324bd6a43405818e259c8c"},{"cell_type":"markdown","metadata":{"cell_id":"432b15e88fd945e3aef49a1c1f3cebe3","deepnote_cell_type":"markdown"},"source":"<H3>Step 2: Explore and familiarize with the dataset</H3>","block_group":"432b15e88fd945e3aef49a1c1f3cebe3"},{"cell_type":"markdown","metadata":{"cell_id":"f1a964bce0894cfd96d9a59cf399180f","deepnote_cell_type":"markdown"},"source":"<b>Q1: Analyse the dataset and answer the following:</b> \n- What is the number of records, \n- What is the number of attributes present with the preprocessing we provided, and \n- What is the list of attribute names.\n- Are there missing values that could create biases","block_group":"f1a964bce0894cfd96d9a59cf399180f"},{"cell_type":"markdown","metadata":{"cell_id":"8f66419b4c594638998d1e51a3f48450","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-danger\">\n<b>Note:</b> If you encounted any errors in the following cell add the files \"german.doc\" and \"german.data\" to the folder <br>\n\"dist-packages/aif360/data/raw/german/\" under your python path you should get the same instructions in the error message.\n\nYou can find the files in Brightspace or download them from: <br>\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data<br>\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n    </div>","block_group":"8f66419b4c594638998d1e51a3f48450"},{"cell_type":"code","metadata":{"cell_id":"bba5ecd986ba4cc388b09c3652dcc5fc","source_hash":"debcea0a","execution_start":1632728836557,"execution_millis":879,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# Instanciating the German credit dataset\ndataset_gcredit = preproc_and_load_data_german()\nprint(type(dataset_gcredit))","block_group":"bba5ecd986ba4cc388b09c3652dcc5fc","execution_count":null,"outputs":[{"name":"stderr","text":"ERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nIOError: [Errno 2] No such file or directory: '/root/venv/lib/python3.7/site-packages/aif360/datasets/../data/raw/german/german.data'\nTo use this class, please download the following files:\n\n\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n\nand place them, as-is, in the folder:\n\n\t/root/venv/lib/python3.7/site-packages/aif360/data/raw/german\n\nTraceback (most recent call last):\n  File \"/root/venv/lib/python3.7/site-packages/aif360/datasets/german_dataset.py\", line 79, in __init__\n    na_values=na_values)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\", line 610, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\", line 462, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\", line 819, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1050, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1867, in __init__\n    self._open_handles(src, kwds)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1368, in _open_handles\n    storage_options=kwds.get(\"storage_options\", None),\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/common.py\", line 652, in get_handle\n    newline=\"\",\nFileNotFoundError: [Errno 2] No such file or directory: '/root/venv/lib/python3.7/site-packages/aif360/datasets/../data/raw/german/german.data'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_164/4107702268.py\", line 2, in <module>\n    dataset_gcredit = preproc_and_load_data_german()\n  File \"/tmp/ipykernel_164/1938112627.py\", line 116, in preproc_and_load_data_german\n    custom_preprocessing=custom_preprocessing)\n  File \"/root/venv/lib/python3.7/site-packages/aif360/datasets/german_dataset.py\", line 89, in __init__\n    sys.exit(1)\nSystemExit: 1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n    return f(*args, **kwargs)\n  File \"/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"/usr/local/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\nAttributeError: 'tuple' object has no attribute 'tb_frame'\n","output_type":"stream"},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m~/venv/lib/python3.7/site-packages/aif360/datasets/german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[1;32m     78\u001b[0m             df = pd.read_csv(filepath, sep=' ', header=None, names=column_names,\n\u001b[0;32m---> 79\u001b[0;31m                              na_values=na_values)\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             )\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/venv/lib/python3.7/site-packages/aif360/datasets/../data/raw/german/german.data'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_164/4107702268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instanciating the German credit dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset_gcredit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc_and_load_data_german\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_gcredit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_164/1938112627.py\u001b[0m in \u001b[0;36mpreproc_and_load_data_german\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m                                 for x in D_features]},\n\u001b[0;32m--> 116\u001b[0;31m         custom_preprocessing=custom_preprocessing)\n\u001b[0m","\u001b[0;32m~/venv/lib/python3.7/site-packages/aif360/datasets/german_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemExit\u001b[0m: 1","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2054\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2055\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2056\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    632\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}],"outputs_reference":"dbtable:cell_outputs/ca2564ea-c77d-4b0b-9174-d5d5bf840d2c","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"a0c52993d82749c9b322c85ced43e712","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> The documentation of \"AIF360 - German credit data\" dataset  can be found <a href=\"https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.GermanDataset.html\">[HERE]</a>. \n\n\nTake a look at documentation of AIF360 and use existing methods to explore the dataset instance how to access the features with:<br> `dataset_gcredit.features`. \n\nYou are also free to transform the dataset into a pandas dataframe to extract the needed information.\nUse <br>\n    `pd_gdata = pd.DataFrame(dataset_gcredit.features, columns=dataset_gcredit.feature_names)` <br>\n    to create the pandas dataframe\n</div> ","block_group":"a0c52993d82749c9b322c85ced43e712"},{"cell_type":"markdown","metadata":{"cell_id":"784f3e9d2edc408fab06c8db90d90698","deepnote_cell_type":"markdown"},"source":"- ","block_group":"784f3e9d2edc408fab06c8db90d90698"},{"cell_type":"code","metadata":{"cell_id":"d8d80c54fc7848e083638ef0e65b03cc","source_hash":"c01ccdae","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"### Answer by writing the code in this cell (or create more cells if needed):###\ndataset = pd.DataFrame(dataset_gcredit.features, columns=dataset_gcredit.feature_names)\nprint(dataset)\n# Number of records:\nprint(len(dataset))\n# Number of features:\nprint(len(dataset.columns))\n# Feature names:\nprint(dataset.columns.values)\n#Number of missing values for each attribute\nprint(dataset.isin(['NA']).sum(axis=0))","block_group":"d8d80c54fc7848e083638ef0e65b03cc","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"54bb97d0e84f4fc4ac3cb466d87d3dec","deepnote_cell_type":"markdown"},"source":"<br><br>","block_group":"54bb97d0e84f4fc4ac3cb466d87d3dec"},{"cell_type":"markdown","metadata":{"cell_id":"423577562db1433da55e074e6a2fa0d8","deepnote_cell_type":"markdown"},"source":"<H3>Step 3: Identify protected attributes and proxies</H3>","block_group":"423577562db1433da55e074e6a2fa0d8"},{"cell_type":"markdown","metadata":{"cell_id":"677c7b82290b4e15a6489bc69ac42520","deepnote_cell_type":"markdown"},"source":"<b>Q2: Identification of protected attributes</b>\n\na) Study the dataset and its documentation and identify which attributes that might raise unfairness concerns and should be considered protected (according to the law). Explain, in your opinion, why are these attributes protected provide exaples of bias or unfaireness for each identified attribute. ","block_group":"677c7b82290b4e15a6489bc69ac42520"},{"cell_type":"markdown","metadata":{"cell_id":"5c574c5f597c4034ba2692fd7ebe1a0e","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> \nTake a look at the following documents<br>\n<a href=\"https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73\">(1) Discrimination, Artificial Intelligence, and Algorithmic Decision-Making (2018)</a><br>\n<a href=\"http://ec.europa.eu/social/BlobServlet?docId=1691&langId=en&usg=AOvVaw3vI30bO3jisairH2Z7-nSl\">(2) Age discrimination and European Law (2005)</a>. \n<div> \n\n","block_group":"5c574c5f597c4034ba2692fd7ebe1a0e"},{"cell_type":"markdown","metadata":{"cell_id":"9f6eea8f694d4011a1058ab2825c2e4a","deepnote_cell_type":"markdown"},"source":"The immediately evident protected attributes are sex, age and foreign worker. Also two less obvious ones is discussed, namely skilled worker and personal status.\n- For the sex, a distinction between genders is made, which is directly mentioned in [1]. Historically, women worked less, especially when married, which could create a bias against woman when trying to apply for a loan.\n- For the age, it is also very clearly mentioned that distinctions should not be made based on this [2]. This is because younger people generally earn less than older people and have less property. This could lead to a negative bias towards young people when applying for a loan, which is unfair for young people that might earn more.\n- For the foreign worker attribute, it is clear that a distinction is made based on nationality. Furthermore, it also includes a minority. Because a non-German nationality might on average have less money, they might get a lower chance may earn less. Also, if non-German people earn way more, this would cause unfairness towards German people. This is because based on the German nationality, the chance of getting a loan would be lower (in this hypothetical situations). \n- For the the skill-level, a distinction is made for resident and non-residents. Thereby, it inherently differentiates between the nationalities, which is seen as discriminatory. There, a similar example can be used as the foreign workers, but then only for unskilled workers of different nationalities. Although the skill-level itself does not have anything to do with nationality, it is still considered a protected attribute because of the distinction between nationalities.\n- Lastly, for the personal status, different categories are there depending on the gender. Because of this, this category can be directly linked to the gender, which is something that should not affect someone's chances of getting a loan. ","block_group":"9f6eea8f694d4011a1058ab2825c2e4a"},{"cell_type":"markdown","metadata":{"cell_id":"2668c330dcbf4de09f1d2e48a1d304e8","deepnote_cell_type":"markdown"},"source":"b) Study the dataset and its documentation and identify any further \"non-protect\" attributes that could cause  unfairenesses. Explain your reasoning. provide examples of bias or unfairenesse related to each attribut.","block_group":"2668c330dcbf4de09f1d2e48a1d304e8"},{"cell_type":"markdown","metadata":{"cell_id":"1bcde6c041584ce7a3c10588fb55e9b6","deepnote_cell_type":"markdown"},"source":"- The residence since attribute could be unfair to people who could be granted a loan but who is not a residence for a long time. It seems to have little correlation to whether this person should get a loan or not, as the amount of money or credit this person has is not affected by the time of his/her residence.\n- For the telephone attribute, an unfair situation is also not unimaginable. Whether someone owns a phone should not be an indication of how likely they are to be granted a loan. For example, a rich person without a phone should still get a loan as it has nothing to do with him being rich.\n- Lastly, the skill-level attribute could be unfair for another reason than mentioned in Q2a. Although there is a correlation between skilled work and earning much money, this is not a certain thing. Someone who does a niche job that not many people want to do could still earn a lot of money despite it being unskilled work. Therefore, the skill-level should not be used to determine whether someone is granted for a loan.","block_group":"1bcde6c041584ce7a3c10588fb55e9b6"},{"cell_type":"markdown","metadata":{"cell_id":"15cbec6f4e084c2f993feaad381bdea7","deepnote_cell_type":"markdown"},"source":"<br><br>","block_group":"15cbec6f4e084c2f993feaad381bdea7"},{"cell_type":"markdown","metadata":{"cell_id":"f6abd50077b14ca8b5d8833346396c99","deepnote_cell_type":"markdown"},"source":"<b>Q3:  Identification of \"spurious\" proxies</b>\n\na) Find the proxies for the attribute \"sex\".\n\nb) Find proxies for one additional protected attribut you identified in Q2-a.\n\nc) In your opinion, why do we want to identify proxies for protected attributes in a dataset? How should you handle the proxies?","block_group":"f6abd50077b14ca8b5d8833346396c99"},{"cell_type":"markdown","metadata":{"cell_id":"fd4d634d583d4b03a449898d3316f237","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b> Tip: </b>A proxy attribute <i>Ap</i>  is an attribute that has a similar distribution as another attribute <i>Ax</i>, so having access to the proxy attribute <i>Ap</i> provides a good knowledge of the other attribute <i>Ax</i>. For instance, in the US the zipcode is a powerful proxy for race and education, the zipcode combined with websites visited is an even more powerful proxy, names in certain languages are strong proxies for gender, etc.<br>\n\nThe simplest way to identify proxy attributes for a protected attribute <i>Ax</i> is to compute the correlation of <i>Ax</i>  with each other attributes in the dataset. The higher the corrolation the higher the likelihood an attribute is a proxy of <i>Ax</i> <br>\n\nYou can use the `corr()` function of the pandas library to compute the correlation between two attributes\n</div> \n\n\n   ","block_group":"fd4d634d583d4b03a449898d3316f237"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"423a5c63a6c24e8aa2a36a953620c177","source_hash":"ade67a35","execution_start":1632402592977,"execution_millis":400,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"dataset = pd.DataFrame(dataset_gcredit.features, columns=dataset_gcredit.feature_names)\ndataset.corr(method ='spearman')\n","block_group":"423a5c63a6c24e8aa2a36a953620c177","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'dataset_gcredit' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_306/613324030.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_gcredit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_gcredit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'kendall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset_gcredit' is not defined"]}],"outputs_reference":"dbtable:cell_outputs/47992051-576a-43cc-9e1b-9b864c958c3a","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"1abbfc88cd124eceacff5b11363a21c3","deepnote_cell_type":"markdown"},"source":"#Answer\na) \n1. According to the correlation among all tthe columns, the correlation between \"sex\" and \"personal_status=single\" is 0.738036, which has a similar distribution, thus \"personal_status=single\" can be indentified as one of the proxies of attribute \"sex\".\n2. The correlation between \"sex\" and \"personal_status=divorced/separated/married\" is -1.0000, which has an exaclty opposite distribution, which is because in the german.doc, the attribute 9 of personal status and sex defines the A92 as female divorced/separated/married and no definition for male divorced/separated/married. Which indicates the attribute \"personal_status=divorced/separated/married\" is directly relate to \"sex\" and can be indentified as one of the proxies of attribute \"sex\".\nb) We choose “skill_level=A171\".\nThe correlation between \"skill_level=A171\" and \"employment=unemployed\" is 0.413756 which indicates a low correlation. The origin of this correlation can be found in the definition of attribute \"skill_level=A171\", which is \"unemployed/unskilled-non-resident\" according to the german.doc file.\n\nc) We want to identify the proxies because we don't want any protected attributes to cause unfairness. One strategy to mitigate unfairness is to change the data in such a way that lower correlation is seen with the protected attribute. For the personal status, this could be done by changing the categories to ungendered categories. However, it should be checked if this still causes unfairness. Another approach would be to remove the data that have high correlation with the protected attribute. \n\n","block_group":"1abbfc88cd124eceacff5b11363a21c3"},{"cell_type":"markdown","metadata":{"cell_id":"ed04934c9d234e78834afef48507f374","deepnote_cell_type":"markdown"},"source":"<br>\n<b>Q4: Data skews and Representation biases</b>\n\na) Is the dataset we are working with representative of the German population with regard to age. <br>\nAdd any needed code or analysis to briefely justify your answer<br>\n\nb) Is the dataset we are working with representative of the German population with regard to gender. <br>\nAdd any needed code or analysis to briefely justify your answer","block_group":"ed04934c9d234e78834afef48507f374"},{"cell_type":"markdown","metadata":{"cell_id":"75af361b87cf4528b8bee735f91bf5dd","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b> Tip: </b> You can find demographic information from Wikipedia <a href=https://en.wikipedia.org/wiki/Demographics_of_Germany>[Here]</a>\n    \nGo to section <b><i>Demographic statistics</i></b> take a closer look at the most racent  <b><i>Age structure</i></b> data (it should be from 2018). Use this data to build a distribution of german population across age, then across gender and compare it to the distributions from <b><i>the German credit data</i></b> we are working with.\n\nIt is up to you how you want to justify your answer, however using visualizations will provide more points (i.e., plots and diagram)\n</div>\n    ","block_group":"75af361b87cf4528b8bee735f91bf5dd"},{"cell_type":"code","metadata":{"cell_id":"e6d3be9cd00b4394bc57eb72a6c14f37","source_hash":"e4c55447","execution_start":1632726122816,"execution_millis":160,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Answer with the code here \n# No code is required however it will make your reasening clearer to the assessor \nmale_25_plus = 30101632\nmale_25_min = 9392699\nfemale_25_plus = 32005225\nfemale_25_min = 8958181\nfig, ax = plt.subplots(figsize=(8,4), ncols=2)\narray_1 = list(dataset['age'])\narray_2 = list(dataset['sex'])\nax[0].set_title('dataset')\n\nax[1].set_title('Wikipedia (2018)')\n\nax[0].hist(x=array_2, bins=2)\nax[0].set_xticks([])\nax[0].text(0.18, -30, 'female')\nax[0].text(0.68, -30, 'male')\nax[1].bar(['female', 'male'], (female_25_min+female_25_plus, male_25_min+male_25_plus))\nfor i in range(2):\n  ax[i].set_xlabel('sex')\n\nplt.tight_layout()\n\nfig, ax = plt.subplots(figsize=(8,4),ncols=2)\n\nax[0].hist(x=array_1, bins = 2)\nax[0].set_xticks([])\nax[0].text(0.18, -30, 'Young')\nax[0].text(0.68, -30, 'Old')\nax[0].set_title('dataset')\nax[1].set_title('Wikipedia (2018)')\nax[1].bar(['Young','Old'], (female_25_min+male_25_min, male_25_plus+female_25_plus))\nfor i in range(2):\n  ax[i].set_xlabel('age')\nplt.tight_layout()\n\n\nfig, ax = plt.subplots(figsize=(8,4), ncols=2)\narray_1 = np.array([i for x, i in enumerate(dataset['age'].values) if dataset['sex'].iloc[x]==1])\narray_2 = np.array([i for x, i in enumerate(dataset['age'].values) if dataset['sex'].iloc[x]==0])\nax[0].set_title('dataset')\n\nax[1].set_title('Wikipedia (2018)')\n\nax[0].hist(x=array_1, bins=2)\nax[0].set_xticks([])\nax[0].text(0.14, -30, 'Young Male')\nax[0].text(0.64, -30, 'Old Male')\nax[1].bar(['Young Male','Old Male'], (male_25_min, male_25_plus))\nfor i in range(2):\n  ax[i].set_xlabel('age')\n\nplt.tight_layout()\n\nfig, ax = plt.subplots(figsize=(8,4),ncols=2)\nax[0].set_title('dataset')\n\nax[1].set_title('Wikipedia (2018)')\nax[0].hist(x=array_2, bins = 2)\nax[0].set_xticks([])\nax[0].text(0.1, -30, 'Young Female')\nax[0].text(0.6, -30, 'Old Female')\nax[1].bar(['Young Female','Old Female'], (female_25_min, female_25_plus))\nfor i in range(2):\n  ax[i].set_xlabel('age')\nplt.tight_layout()\n\n","block_group":"e6d3be9cd00b4394bc57eb72a6c14f37","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'plt' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_132/2620195710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Answer with the code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# No code is required however it will make your reasening clearer to the assessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0marray_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0marray_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}],"outputs_reference":"dbtable:cell_outputs/3f0e82c1-a256-47c0-abb3-3f3a338dc684","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"23b4da88a7aa40a581c8d82580de39f0","deepnote_cell_type":"markdown"},"source":"Q4a:\n- For the age gap, we see that the division does not show incredible under or over representation.\nQ4b:\n- We see that the female gender is heavily underrepresented in the data, since the number of females is approximately equal to the number of man according to Wikipedia. This is probably due to the fact that historically males were often responsible for financial tasks. \n\nBonus:\nOne downside of using bargraphs/histograms is that they do not show the correlation between the sex and age, which leaves us wondering whether young and old females are equally underrepresented or whether this is different too. Therefore, we add another barchart/histogram for young vs old separately for males and females.\nIt seems that within the distribution of males, the young male is underrepresented. Interestingly, the young female is relatively overrepresented. Probably, this is due to the fact that old females tend to be married more often. \n","block_group":"23b4da88a7aa40a581c8d82580de39f0"},{"cell_type":"markdown","metadata":{"cell_id":"f7207d811d5340fb90e1bc4bca39976e","deepnote_cell_type":"markdown"},"source":"<b>Q5: Data skews</b> \n\nIs there a skew towards certain groups:<br>\na) Analyse the dataset, and report the numbers of male / female with bad/good credit. Do the same for \"old\" / \" young\" people in the datset. Normalize these numbers respectively over the total number of males/females, \"old\"/\"young\" for a fair comparison. For that, you can consider having 50 individuals for each of these groups.\n\nb) Brieflt describe your findings and explain the impacts (on faireness) of using this dataset as training data (if any)","block_group":"f7207d811d5340fb90e1bc4bca39976e"},{"cell_type":"markdown","metadata":{"cell_id":"d5e62e1eab9d40e2a6d29c99fa5b602e","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b> Tip: </b> We provide a function for Normalised count per attribut and lable you are free to use it or implement your own method \n    \n`getNormalizedCount()`\n</div>\n    ","block_group":"d5e62e1eab9d40e2a6d29c99fa5b602e"},{"cell_type":"code","metadata":{"cell_id":"b15235266dc74600b1af09baa659f804","source_hash":"2d78a9c4","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"\n# Normalised count per attribut and lable \ndef getNormalizedCount(pd_train_data, protected_attribute, label):\n    unnormalized_count = pd_train_data[[protected_attribute, label]].value_counts()\n    counts = {}\n    for attribute_value in pd_train_data[[protected_attribute]].value_counts().keys():\n        counts[attribute_value[0]] = pd_train_data[[protected_attribute]].value_counts()[attribute_value]\n    normalized_count = unnormalized_count[:]\n    for attribute_value, credit_value in pd_train_data[[protected_attribute, label]].value_counts().keys():\n        normalized_count[attribute_value, credit_value] = normalized_count[attribute_value, credit_value] * (50 / counts[attribute_value])\n    return normalized_count\n\n# add the credit labels to the data set.\ndataset[\"credit\"] = dataset_gcredit.labels\n\n# normalize_count_age = getNormalizedCount(dataset, 'age', 'credit')\n# print(normalize_count_age)\n# normalize_count_sex = getNormalizedCount(dataset, 'sex', 'credit')\n# print(normalize_count_sex)","block_group":"b15235266dc74600b1af09baa659f804","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"c53dc8394dba4b99b7d32b222ab2f609","source_hash":"841f0c74","execution_start":1632734519464,"execution_millis":24,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# male/female with good/bad credits\n\ndataset_1_and = dataset[(dataset['sex']==1.0) & (dataset['number_of_credits'] == 1.0)]\nprint('Number of male with good credits is '+ str(len(dataset_1_and))+ '.')\n\ndataset_2_and = dataset[(dataset['sex']==1.0) & (dataset['number_of_credits'] == 2.0)]\nprint('Number of male with bad credits is '+ str(len(dataset_2_and))+ '.')\n\ndataset_3_and = dataset[(dataset['sex']==0.0) & (dataset['number_of_credits'] == 1.0)]\nprint('Number of female with good credits is '+ str(len(dataset_3_and))+ '.')\n\ndataset_4_and = dataset[(dataset['sex']==0.0) & (dataset['number_of_credits'] == 2.0)]\nprint('Number of female with bad credits is '+ str(len(dataset_4_and))+ '.')\n\n# old/young with good/bad credits\ndataset_5_and = dataset[(dataset['age']==1.0) & (dataset['number_of_credits'] == 1.0)]\nprint('Number of old people with good credits is '+ str(len(dataset_5_and))+ '.')\n\ndataset_6_and = dataset[(dataset['age']==1.0) & (dataset['number_of_credits'] == 2.0)]\nprint('Number of old people with bad credits is '+ str(len(dataset_6_and))+ '.')\n\ndataset_7_and = dataset[(dataset['age']==0.0) & (dataset['number_of_credits'] == 1.0)]\nprint('Number of young people with good credits is '+ str(len(dataset_7_and))+ '.')\n\ndataset_8_and = dataset[(dataset['age']==0.0) & (dataset['number_of_credits'] == 2.0)]\nprint('Number of young people with bad credits is '+ str(len(dataset_8_and))+ '.')\n\nnormalize_count_age = getNormalizedCount(dataset, 'age', 'credit')\nprint(normalize_count_age)\nnormalize_count_sex = getNormalizedCount(dataset, 'sex', 'credit')\nprint(normalize_count_sex)\n\n# ADD code here to visualise the results for both you can use stacked bar plots from pandas toolkit\n#<your dataframe>.size().unstack().plot(kind='bar', stacked=True)\nfig, ax = plt.subplots(ncols=2, figsize = (8,4))\nax[0].bar(['Old', 'Young'], [36,28], label= 'Good credit')\nax[0].bar(['Old', 'Young'], [13,21], bottom = [36,28], label= 'Bad credit' )\n\nax[1].bar(['Male', 'Female'],[36,32], label = 'Good credit')\nax[1].bar(['Male', 'Female'],[13,17], bottom=[36,32],label='Bad credit')\nfor i in ax:\n  i.legend()\n","block_group":"c53dc8394dba4b99b7d32b222ab2f609","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_164/3247029085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### YOUR ANSWER HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ADD code here to print the AGE-CREDIT distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset_5_and\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'number_of_credits'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of old with good credits is '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_5_and\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"]}],"outputs_reference":"dbtable:cell_outputs/04b1fa13-041c-47d6-a784-cdbf1e359b45","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"61d648aa6a504c22956b8a116b4ccaae","deepnote_cell_type":"markdown"},"source":"Q5a: \nNumber of male with good credits is 416.\nNumber of male with bad credits is 246.\nNumber of female with good credits is 217.\nNumber of female with bad credits is 87.\nNumber of old people with good credits is 488.\nNumber of old people with bad credits is 289.\nNumber of young people with good credits is 145.\nNumber of young people with bad credits is 44.\nQ5b:\nWe see that there is a negative bias towards young people and females. From this data, the AI would learn a relationship in which females and young people have worse credit than males and old people, respectively. Thus, when the AI is implemented, a younger person/female would have automatically a lower chance of being granted a loan because of their age or gender.","block_group":"61d648aa6a504c22956b8a116b4ccaae"},{"cell_type":"markdown","metadata":{"cell_id":"78b5fe8d6cc24796bf1f500d9a3cd5d1","deepnote_cell_type":"markdown"},"source":"<br><br>","block_group":"78b5fe8d6cc24796bf1f500d9a3cd5d1"},{"cell_type":"markdown","metadata":{"cell_id":"a03e69c9674748299573888d79283287","deepnote_cell_type":"markdown"},"source":"<H3> Step 4: In-Prosessing Biases </H3>","block_group":"a03e69c9674748299573888d79283287"},{"cell_type":"markdown","metadata":{"cell_id":"1b5753f9d0164ad1a730bd4f0a2f16d5","deepnote_cell_type":"markdown"},"source":"<b>Q6: We will apply in-processing mitigation technique to alliviate the <i>age</i> biase in the German credit data</b>\n\na) Set the privilege and unprivilaged age group based on the findings of question Q5-a (answer in the text then add the variables 0 or 1 to the code below). Provide a very brief justification for your answer\n","block_group":"1b5753f9d0164ad1a730bd4f0a2f16d5"},{"cell_type":"markdown","metadata":{"cell_id":"d1eca41bcc9043a2b1ac7c1cace3b2af","deepnote_cell_type":"markdown"},"source":"Q6A\n- In the previous question we saw that the young people were at a disadvantage. Thus, the privileged class is the old group, which in the dataset has a value of 1 and the unprivileged group is the young group, which has a value of 0.","block_group":"d1eca41bcc9043a2b1ac7c1cace3b2af"},{"cell_type":"code","metadata":{"cell_id":"6a3a91f564cd48eab365853aab81b9d6","source_hash":"1d6b2bd3","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Add the code for question a) here\n# code = 1: is old above 25\n# code = 0: is young under 25\n\nprivileged_code = 1 #add the write code here\nunprivileged_code = 0 #add the write code here","block_group":"6a3a91f564cd48eab365853aab81b9d6","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"fc104ed2ba804f7880b6d1929eaa5051","source_hash":"a784eb12","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# We start by defining the privilaged and unprivileged \nprivileged_groups = [{'age': privileged_code}] \nunprivileged_groups = [{'age': unprivileged_code}] ","block_group":"fc104ed2ba804f7880b6d1929eaa5051","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"6d874c56cce84129a68e9ad5b4179bb0","deepnote_cell_type":"markdown"},"source":"<b>Preparation for training a classifier.</b><br>\nWe will  divide the dataset into a training and a test subsets.\nWe define them respectively as 70% and 30% of the whole data.\nWe will use the following code to do so.","block_group":"6d874c56cce84129a68e9ad5b4179bb0"},{"cell_type":"code","metadata":{"cell_id":"5222a17d420e41799fd40ee912b2859c","source_hash":"e530d270","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"dataset_gcredit_train, dataset_gcredit_test = \\\n    dataset_gcredit.split([0.7], shuffle=True, seed=1)","block_group":"5222a17d420e41799fd40ee912b2859c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"f428fa58b4424640865d53780a881508","deepnote_cell_type":"markdown"},"source":"<b>Faireness before mitigation</b><br>\nBelow we are using several faireness metrics from AIF360 toolkint to evaluate fairenesse metrics before appling the inprocessing mitigation","block_group":"f428fa58b4424640865d53780a881508"},{"cell_type":"code","metadata":{"cell_id":"90f048ec7ba94fc0a5cca658482c74d6","source_hash":"dea81c7","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"metric_orig_train = BinaryLabelDatasetMetric(dataset_gcredit_train, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\nprint(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = {:.3f}\".format(metric_orig_train.mean_difference()))","block_group":"90f048ec7ba94fc0a5cca658482c74d6","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"725f67f4634e47d89e0d37ace9b67574","deepnote_cell_type":"markdown"},"source":"Get classifier without fairness constraints","block_group":"725f67f4634e47d89e0d37ace9b67574"},{"cell_type":"code","metadata":{"cell_id":"87c21a5e51a84c518853405a1c6d992f","source_hash":"845cdf93","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"biased_model = MetaFairClassifier(tau=0, sensitive_attr=\"sex\", type=\"fdr\").fit(dataset_gcredit_train)","block_group":"87c21a5e51a84c518853405a1c6d992f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"bfb4b13d4cdc461695dd5cb954d9ac0d","deepnote_cell_type":"markdown"},"source":"Apply the unconstrained model to test data","block_group":"bfb4b13d4cdc461695dd5cb954d9ac0d"},{"cell_type":"code","metadata":{"cell_id":"0842b9069d68447582f76a6afb4346b5","source_hash":"d081d622","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"dataset_bias_test = biased_model.predict(dataset_gcredit_test)","block_group":"0842b9069d68447582f76a6afb4346b5","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"82d41bfc5baa4e2fa74d6a538b67f775","deepnote_cell_type":"markdown"},"source":"Build and test the \"biased\" classifier","block_group":"82d41bfc5baa4e2fa74d6a538b67f775"},{"cell_type":"code","metadata":{"cell_id":"36a4713808004993a3e946a1db3c9810","source_hash":"5b8540e","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"classified_metric_bias_test = ClassificationMetric(dataset_gcredit_test, dataset_bias_test,\n                                                   unprivileged_groups=unprivileged_groups,\n                                                   privileged_groups=privileged_groups)\nprint(\"Test set: Classification accuracy = {:.3f}\".format(classified_metric_bias_test.accuracy()))\nTPR = classified_metric_bias_test.true_positive_rate()\nTNR = classified_metric_bias_test.true_negative_rate()\nbal_acc_bias_test = 0.5*(TPR+TNR)\nprint(\"Test set: Balanced classification accuracy = {:.3f}\".format(bal_acc_bias_test))\nprint(\"Test set: Disparate impact = {:.3f}\".format(classified_metric_bias_test.disparate_impact()))\nfdr = classified_metric_bias_test.false_discovery_rate_ratio()\nfdr = min(fdr, 1/fdr)\nprint(\"Test set: False discovery rate ratio = {:.3f}\".format(fdr))","block_group":"36a4713808004993a3e946a1db3c9810","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"f4b9cbf9693841408cbade6009f10cdb","deepnote_cell_type":"markdown"},"source":"<br>\n<b> Q6 -</b>\nb) Run the code above and explain the results: briefly describe each metric and the interpretation of the values.\n\nMetrics:<br>\n- Difference in mean outcomes between unprivileged and privileged groups\n- Classification accuracy\n- Balanced classification accuracy\n- Disparate impact\n- False discovery rate ratio\n\n\n","block_group":"f4b9cbf9693841408cbade6009f10cdb"},{"cell_type":"markdown","metadata":{"cell_id":"79a45329fcc04ed6902debd9d3051713","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b> Tip: </b> Make use of the documentation of <a href=https://aif360.readthedocs.io/en/latest/index.html><b>AIF360</b></a>, and your own search to understaind the metrics and to be able to interpret them.\n</div>","block_group":"79a45329fcc04ed6902debd9d3051713"},{"cell_type":"markdown","metadata":{"cell_id":"599cc15dd1e1433ca10b3f55d71c639d","deepnote_cell_type":"markdown"},"source":"- Based on the difference in mean outcomes between unprivileged and privileged groups, we can conclude that in the priviliged group, there is an 11.9% higher absolute chance to obtain a positive result. Clearly, the biased data has an impact on the classification.\n- Classification accuracy shows the proportion of correctly classified entities. This shows that the AI was correct in 63.7% of the cases.\n- The balanced classification accuracy shows the mean value for the true positive and true negative rate. Since the value is 0.446, we can see that there is a difference between the true positive and true negative rate. For the true negative rate, an accuracy of 0.0 is achieved while the true positive rate amounts to 0.893. This is extremely unbalanced.\n- Disparate impact is a division between the positive rates of the unprivileged and privileged groups, which amounts to 0.810. This tells us more about the relative chance of being granted money. Thus, the unprivileged groups have a 100%-81% = 19% lower chance to obtain a grant than the privileged groups.\n- The false discovery rate ratio is the false positive rate divided by the total number of positive results. In this case, 51% of the positive classifications were falsely classified as positive. ","block_group":"599cc15dd1e1433ca10b3f55d71c639d"},{"cell_type":"markdown","metadata":{"cell_id":"27788bb358014b75b39901dfc36f2ce5","deepnote_cell_type":"markdown"},"source":"<b> Train a debiased classifier </b><br>\nIn the following we will apply an in-processing debiasin technique <b><i>\"Meta-Algorithm for fair classification\"</i></b>. This debiesing technique operates with a faireness constraint i.e., by optimising for faireness metrics. You can read more about it <a href=https://arxiv.org/pdf/1806.06055.pdf>[HERE]</a><br>\nFor this example we will to optimize for the <i><b> the fals discovery rate (fdr)</b></i> and sensitive attribute <i><b> age </b></i>\n    \nApply the debiased model to training data and train the <b><i>\"debiased\"</i></b> classifier","block_group":"27788bb358014b75b39901dfc36f2ce5"},{"cell_type":"code","metadata":{"cell_id":"49f0b9c6e1c94ec181eea1aeffcedae7","source_hash":"c37b9d2d","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"debiased_model = MetaFairClassifier(tau=0.7, sensitive_attr=\"age\", type=\"fdr\").fit(dataset_gcredit_train)","block_group":"49f0b9c6e1c94ec181eea1aeffcedae7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"1f7a473fc20d4f30b5b1f1881c8acba1","deepnote_cell_type":"markdown"},"source":"Apply the debiased classifier to test data","block_group":"1f7a473fc20d4f30b5b1f1881c8acba1"},{"cell_type":"code","metadata":{"cell_id":"80d53250f5d24cebb1d0893d0e5c509d","source_hash":"525807a4","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"dataset_debiasing_test = debiased_model.predict(dataset_gcredit_test)","block_group":"80d53250f5d24cebb1d0893d0e5c509d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"a4e6c25ef43d4e9186ae82d211b09dac","deepnote_cell_type":"markdown"},"source":"Compute the same faireness metrics for the <b><i>\"debiased\"</i></b> data and classifier","block_group":"a4e6c25ef43d4e9186ae82d211b09dac"},{"cell_type":"code","metadata":{"cell_id":"e34e18b12eda42c2a4dc6f442bcfcbfb","source_hash":"10e4b350","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n                                             unprivileged_groups=unprivileged_groups,\n                                             privileged_groups=privileged_groups)\n\nprint(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = {:.3f}\".format(metric_dataset_debiasing_test.mean_difference()))","block_group":"e34e18b12eda42c2a4dc6f442bcfcbfb","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"20e59833b90a49b8a6d269682c4d7978","source_hash":"7fad4000","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"classified_metric_debiasing_test = ClassificationMetric(dataset_gcredit_test, \n                                                 dataset_debiasing_test,\n                                                 unprivileged_groups=unprivileged_groups,\n                                                 privileged_groups=privileged_groups)\nprint(\"Test set: Classification accuracy = {:.3f}\".format(classified_metric_debiasing_test.accuracy()))\nTPR = classified_metric_debiasing_test.true_positive_rate()\nTNR = classified_metric_debiasing_test.true_negative_rate()\nbal_acc_debiasing_test = 0.5*(TPR+TNR)\nprint(\"Test set: Balanced classification accuracy = {:.3f}\".format(bal_acc_debiasing_test))\nprint(\"Test set: Disparate impact = {:.3f}\".format(classified_metric_debiasing_test.disparate_impact()))\nfdr = classified_metric_debiasing_test.false_discovery_rate_ratio()\nfdr = min(fdr, 1/fdr)\nprint(\"Test set: False discovery rate ratio = {:.3f}\".format(fdr))\n","block_group":"20e59833b90a49b8a6d269682c4d7978","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"a9e84df62ea84cd0b5e608e40b46587d","deepnote_cell_type":"markdown"},"source":"<br>\n<b> Q6 -</b>\nc) Run the code above and compare the results between the <b><i>\"debiased\"</i></b> and the <b><i>\"biased\"</i></b> classifiers\n","block_group":"a9e84df62ea84cd0b5e608e40b46587d"},{"cell_type":"markdown","metadata":{"cell_id":"2b8ff89e268744d7b836c2e25954a697","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b> Tip: </b> Focus on <b>FDR</b>, <b>Accuracy</b> and <b>Difference in mean outcomes</b>\n</div>","block_group":"2b8ff89e268744d7b836c2e25954a697"},{"cell_type":"markdown","metadata":{"cell_id":"0e9c2379b5ce489e98196cf49721dda3","deepnote_cell_type":"markdown"},"source":"- For the difference in mean outcomes, we see that there is no significant net change of the gap between privileged and unprivileged classes. Now, the unprivileged young group have a decreased absolute chance to get a loan of 11.9%. This is 0.1% higher than for the biased classifier.\n- We see that the debiased classifier has a higher classification accuracy. Evidently, the accuracy is impacted by the debiasing too.\n- The balanced classification accuracy is also higher. This is coherent with the classification accuracy.\n- Also, the Disparate impact is highered when comparing to the biased classification, indicating a higher fairness.\n- We see that the false discovery ratio is higher than for the biased classifier, which indicates that the number of false positives has increased.\n\nSummary:\n\nAs expected, the debiased classification seems to be more fair than the biased classification. Additionally, the accuracy seems to be higher. Interestingly, the FDR has increased, which seems counterintuitive considering that we are debiasing based on the FDR. However, when thinking about it more, we realise that the fairness of the FDR may have increased and the accuracy of the FDR may have suffered from this.","block_group":"0e9c2379b5ce489e98196cf49721dda3"},{"cell_type":"markdown","metadata":{"cell_id":"adff72a760cc47b2b483b86768a0fcf5","deepnote_cell_type":"markdown"},"source":"<br><br>","block_group":"adff72a760cc47b2b483b86768a0fcf5"},{"cell_type":"markdown","metadata":{"cell_id":"bf28c422d92543cb99353b0be6b2b317","deepnote_cell_type":"markdown"},"source":"<H2> Part III. Explainability</H2>\n<i>LO-4. Compare different implementations of fairness metrics and unfairness mitigation approaches.  \n</i>","block_group":"bf28c422d92543cb99353b0be6b2b317"},{"cell_type":"markdown","metadata":{"cell_id":"6b594273ff3b4cd4a7a4544ec5fc22ec","deepnote_cell_type":"markdown"},"source":"In this last part we will use the same scenario from Part II. To explore LIME Local Interpretable Model-Agnostic Explanations. ","block_group":"6b594273ff3b4cd4a7a4544ec5fc22ec"},{"cell_type":"code","metadata":{"cell_id":"dc85d97b83e44af79ac9279a11af5bb4","source_hash":"c622d58c","execution_start":1632728794319,"execution_millis":8,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"#Train model on german credit data dataset\n\ndataset = dataset_gcredit_train  # data to train on\n\nscale = StandardScaler().fit(dataset.features)   # remember the scale\n\nmodel = LogisticRegression()        # model to learn\n\nX_train = scale.transform(dataset.features)      #apply the scale\ny_train = dataset.labels.ravel()\n\n\nmodel.fit(X_train, y_train, sample_weight=dataset.instance_weights)\n\n#save model\nlr_orig = model\nlr_scale_orig = scale","block_group":"dc85d97b83e44af79ac9279a11af5bb4","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'dataset_gcredit_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_132/1824031240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train model on german credit data dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_gcredit_train\u001b[0m  \u001b[0;31m# data to train on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# remember the scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset_gcredit_train' is not defined"]}],"outputs_reference":"dbtable:cell_outputs/5a8f0f89-b198-4543-9679-00ebb49be967","content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"2100138789374c2cbdebfed09b12e526","source_hash":"d2f7a827","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"#Test model on given dataset and find threshold for best balanced accuracy\nimport numpy as np\nfrom tqdm import tqdm\nthresh_arr = np.linspace(0.01, 0.5, 50)\n\nscale = lr_scale_orig\n\nmodel = lr_orig                  #model to test\ndataset = dataset_gcredit_test        #data to test on\n\nX_test = scale.transform(dataset.features)   #apply the same scale as applied to the training data\ny_test = dataset.labels.ravel()\ny_test_pred_prob = model.predict_proba(X_test)\n\n\nbal_acc_arr = []\ndisp_imp_arr = []\navg_odds_diff_arr = []\n    \nfor thresh in tqdm(thresh_arr):\n    y_test_pred = (y_test_pred_prob[:,1] > thresh).astype(np.double)\n\n    dataset_pred = dataset.copy()\n    dataset_pred.labels = y_test_pred\n\n    classified_metric = ClassificationMetric(dataset, \n                                                 dataset_pred,\n                                                 unprivileged_groups=unprivileged_groups,\n                                                 privileged_groups=privileged_groups)\n    metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n                                                 unprivileged_groups=unprivileged_groups,\n                                                 privileged_groups=privileged_groups)\n    \n    TPR = classified_metric.true_positive_rate()\n    TNR = classified_metric.true_negative_rate()\n    bal_acc = 0.5*(TPR+TNR)\n    \n    acc = accuracy_score(y_true=dataset.labels,\n                            y_pred=dataset_pred.labels)\n    bal_acc_arr.append(bal_acc)\n    avg_odds_diff_arr.append(classified_metric.average_odds_difference())\n    disp_imp_arr.append(metric_pred.disparate_impact())\n    \nthresh_arr_best_ind = np.where(bal_acc_arr == np.max(bal_acc_arr))[0][0]\nthresh_arr_best = np.array(thresh_arr)[thresh_arr_best_ind]\n\nbest_bal_acc = bal_acc_arr[thresh_arr_best_ind]\ndisp_imp_at_best_bal_acc = np.abs(1.0-np.array(disp_imp_arr))[thresh_arr_best_ind]\n\navg_odds_diff_at_best_bal_acc = avg_odds_diff_arr[thresh_arr_best_ind]","block_group":"2100138789374c2cbdebfed09b12e526","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"317de0cdf44144d7852f512cf34c43f4","source_hash":"7ae31c9a","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"limeData = LimeEncoder().fit(dataset_gcredit_train)\ns_train = limeData.transform(dataset_gcredit_train.features)\ns_test = limeData.transform(dataset_gcredit_test.features)\n\nscale = lr_scale_orig\n\nmodel = lr_orig                  #model to test\n\n\n\n\nexplainer = lime.lime_tabular.LimeTabularExplainer(s_train ,class_names=limeData.s_class_names, \n                                                   feature_names = limeData.s_feature_names,\n                                                   categorical_features=limeData.s_categorical_features, \n                                                   categorical_names=limeData.s_categorical_names, \n                                                   kernel_width=3, verbose=False,discretize_continuous=True)\n\ns_predict_fn = lambda x: model.predict_proba(scale.transform(limeData.inverse_transform(x)))","block_group":"317de0cdf44144d7852f512cf34c43f4","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"114f6e6862dc4ca18cdeb8f8f3607909","deepnote_cell_type":"markdown"},"source":"<br>\n<b>Q7: Using LIME </b> <br>\na) Provide a short definition of LIME and what it is used for. ","block_group":"114f6e6862dc4ca18cdeb8f8f3607909"},{"cell_type":"markdown","metadata":{"cell_id":"52efa4e0a54a4a9ba710f841c2eb60d0","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b> Tip: </b> Information about LIME can be found <a href=https://arxiv.org/pdf/1602.04938.pdf> [HERE] </a>\n</div>\n    ","block_group":"52efa4e0a54a4a9ba710f841c2eb60d0"},{"cell_type":"markdown","metadata":{"cell_id":"93fdd9d51a6d4dd88ccaaa1d2a7e8218","deepnote_cell_type":"markdown"},"source":"An algorithm that can explain the predictions of any\nclassifier or regressor in a faithful way, by approximating\nit locally with an interpretable model.","block_group":"93fdd9d51a6d4dd88ccaaa1d2a7e8218"},{"cell_type":"markdown","metadata":{"cell_id":"1b52d2c11fed469fade458d4c4a759ae","deepnote_cell_type":"markdown"},"source":"<b>Q7 - </b>\nb) Select two loan applications form the test data set (One classified as \"Good Credit\" and one \"Bad Credit\"). Get the decision explaned by Lime. ","block_group":"1b52d2c11fed469fade458d4c4a759ae"},{"cell_type":"markdown","metadata":{"cell_id":"bf2f141bf9aa4adaa51ab0745fe5aac7","deepnote_cell_type":"markdown"},"source":"<div class=\"alert alert-block alert-info\">\n<b> Tip: </b>Use the following code to explain the classifier decision and print/plot the results from LIME\n\n`i = # the index of the test data entry goes here\nexp = explainer.explain_instance(s_test[i], s_predict_fn, num_features=5)\nexp.as_pyplot_figure()\nprint(\"        Actual label: \" + str(dataset_gcredit_test.labels[i]))`\n\n    \n</div>","block_group":"bf2f141bf9aa4adaa51ab0745fe5aac7"},{"cell_type":"code","metadata":{"cell_id":"5dee31af395c4417b999b3ad06c90e14","source_hash":"f585db3b","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Good Credit explanation\n# Answer with the code here\n\ni = 274\nexp = explainer.explain_instance(s_test[i], s_predict_fn, num_features=5)\nexp.as_pyplot_figure()\nprint(\"        Actual label: \" + str(dataset_gcredit_test.labels[i]))\n\n","block_group":"5dee31af395c4417b999b3ad06c90e14","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"b1b68a5071264590a3dc168847c6e616","source_hash":"e0c7f1d3","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Bad Credit explanation\n# Answer with the code here\n\ni = 0\nexp = explainer.explain_instance(s_test[i], s_predict_fn, num_features=5)\nexp.as_pyplot_figure()\nprint(\"        Actual label: \" + str(dataset_gcredit_test.labels[i]))\n","block_group":"b1b68a5071264590a3dc168847c6e616","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"7f6249b4bfd947c884854d745a69bb30","deepnote_cell_type":"markdown"},"source":"<b>Q7 - </b>\nc) Describe and explaine the results from lime for each of the decisions (Output of Q7-b)","block_group":"7f6249b4bfd947c884854d745a69bb30"},{"cell_type":"markdown","metadata":{"cell_id":"0c351737c7e9488e9ec16a88f5f7cded","deepnote_cell_type":"markdown"},"source":"- Explain a \"Bad Credit\" decision explanation here\n\nThe person that coincides with index number 0 can be noted as a bad credit because the summation of the variables give a negative value for a good credit class. From the local explanation by LIME it can be observed that this person has the following values for its variables:\n\n- This person has obtained a loan to purchase a telephone.\n- The loan must have been paid within or equal to 12 months. The score is negative which means that this condition has not been met.\n- This person has a negative number for the variable 'number of credits', which is a negative sign if this person would require a loan.\n- This person is liable because the value for this variable is negative (<= 1).\n\nAll of this person's variables are negative which means that this loan is a bad credit.","block_group":"0c351737c7e9488e9ec16a88f5f7cded"},{"cell_type":"markdown","metadata":{"cell_id":"3555da5ce4324a5e9b466f60460ca36d","deepnote_cell_type":"markdown"},"source":"- Explain a \"Good Credit\" decision explanation here\n\nThe person that coincides with index number 274 can be noted as a good credit because the summation of the variables is a positive value. From the local explanation by LIME it can be observed that this person has the following values for its variables:\n- This person has obtained the loan to purchase property.\n- The loan must be paid over a lengthy amount of time (over 24 months were given to pay off the loan).\n- This person has either no credit history or only positive credit history, which would mean that its debt has been paid.\n- There are also savings left in this person's account, meaning that there is or still would have been room to pay off extra debt in case the loan was larger.\n\nAs mentioned earlier, this person's variables as mostly positive and its summation is positive resulting in a good credit.","block_group":"3555da5ce4324a5e9b466f60460ca36d"},{"cell_type":"markdown","metadata":{"cell_id":"45661dab45a04fe791ee3bd2d3b4dde5","deepnote_cell_type":"markdown"},"source":"<H3> --------- And of the assignment ---------</H3><br>\n<i>We hope that you enjoyed this lecture.<br> Nadia & Ibo","block_group":"45661dab45a04fe791ee3bd2d3b4dde5"},{"cell_type":"code","metadata":{"cell_id":"daee09aa6bf04992989b61b685df8ead","source_hash":"b623e53d","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"","block_group":"daee09aa6bf04992989b61b685df8ead","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=58b3f704-2113-4f3b-8935-3eda6a61ee3f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"430ebd3e9bc74139bf8c14a30222d80d","deepnote_execution_queue":[]}}